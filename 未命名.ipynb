{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import selenium\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "import re\n",
    "import os   #<[^i]\\w+[^>]*>|</\\w*>\n",
    "PATT_PARSE_IMG=re.compile(r'<img (src=\".*?\").*?>')  #提取html中文本和图片地址\n",
    "PATT_REMOVE_HTML_PART_TAG = re.compile(r'(?!<img)(?P<ss><\\w+[^>]*>|</[a-z-]*>)')   #查找html标签（除img外）用字符串\"\"替换\n",
    "IMG_DIR_PATH = \"E:\\PythonWorkSpace\\HeadlineCrawler\\spider_data\\img\\\\\"\n",
    "Temp_Img_names = []   #[\"xxxx.png\",\"\",...]\n",
    "\n",
    "header={\n",
    "    'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36',\n",
    "    'x-requested-with':'XMLHttpRequest'\n",
    "}\n",
    "\n",
    "article_dic_titel_url = {}\n",
    "def get_data(search_name,offset):\n",
    "    data = {    #构造请求的data\n",
    "        'aid':'24',\n",
    "        'app_name':'web_search',\n",
    "        'offset':offset,\n",
    "        'format':'json',\n",
    "        'keyword':search_name,\n",
    "        'autoload':'true',\n",
    "        'count':'20',\n",
    "        'en_qc':'1',\n",
    "        'cur_tab': '1',\n",
    "        'from': 'search_tab',\n",
    "        'pd':'synthesis',\n",
    "        'timestamp': int(time.time()),\n",
    "        '_signature': '21oMXgAgEBAwjHnl59qFgNtbTUAAIWq5yRBJSZ83MdD56bgu5GDIJxHd0EHk8Y1-DDSzzYJ-ZlFlc5td8NE86Wb3wfbOIt2i-9L7pr2I3.bmY8SCimmZOjMIL2g7TKFO-Lj'\n",
    "    }\n",
    "    url = 'https://www.toutiao.com/api/search/content/?' + urlencode(data)\n",
    "    res = requests.get(url=url,headers=header)\n",
    "    return res\n",
    "\n",
    "def parse_article_list(search_name,offset):\n",
    "    dic = get_data(search_name,offset).json() #转化为json字典\n",
    "    data = dic['data']\n",
    "    if data is not None:    #不为空才开始\n",
    "        for item in data:\n",
    "            if (\"video_duration_str\"not in item and \"has_video\" not in item) or item[\"has_video\"] == False:  #不需要视频文章，视频没有文字\n",
    "                if 'title' in item: #标题\n",
    "                    if 'article_url' in item:  # 文章url\n",
    "                            article_dic_titel_url[item['title']] = item['article_url']\n",
    "\n",
    "def download_img(img_url, img_to_save_url):\n",
    "    r = requests.get(img_url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        try:\n",
    "            open(img_to_save_url, 'wb').write(r.content)  # 将内容写入图片\n",
    "            return True\n",
    "        except Exception:\n",
    "            print(\"保存失败！\")\n",
    "            return False\n",
    "        finally:\n",
    "            del r\n",
    "    return False\n",
    "\n",
    "#文章爬取失败删除图片\n",
    "def del_imgs():\n",
    "    for img_name in Temp_Img_names:\n",
    "        path = IMG_DIR_PATH + img_name\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "\n",
    "#re.sub(...)函数的回调函数\n",
    "def replacement(match):\n",
    "    sentence = match.group(1)\n",
    "    if sentence.startswith(\"src\"):\n",
    "        url = sentence[5:-1]  # 获取url\n",
    "        # 下载图片到本地\n",
    "        img_name = str(time.strftime(\"%Y-%m-%d %H.%M.%S\", time.localtime()))\n",
    "        if download_img(url, IMG_DIR_PATH + img_name + \".png\"):\n",
    "            sentence = \"[图片\" + \"](.\\img\\spider_data\\\\\" + img_name + \".png)\"\n",
    "            Temp_Img_names.append(img_name + \".png\")\n",
    "        else:\n",
    "            sentence = \"[图片\" + \"](\" + url + \")\"\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def parse_article(article_url:str, browser):\n",
    "    title = \"\"\n",
    "    author=\"\"\n",
    "    release_time=\"\"\n",
    "    content=\"\"\n",
    "    if \"toutiao.com\" in article_url:  #头条站点内的文章\n",
    "        # article_url = article_url_convert(article_url)\n",
    "        browser.get(article_url)  # Load page\n",
    "        time.sleep(0.2)  # Let the page load, will be added to the API\n",
    "        try:\n",
    "            title = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/h1\").text\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            title = \"\"\n",
    "\n",
    "        try:\n",
    "            release_time = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/div[1]/span[3]\").text\n",
    "            author = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/div[1]/span[2]\").text\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            try:\n",
    "                release_time = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/div[1]/span[2]\").text\n",
    "                author = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/div[1]/span[1]\").text\n",
    "            except selenium.common.exceptions.NoSuchElementException:\n",
    "                release_time = \"\"\n",
    "                author = \"\"\n",
    "\n",
    "        try:\n",
    "            content_tag = browser.find_element_by_xpath(\"/html/body/div/div[2]/div[2]/div[1]/article\")\n",
    "            content_html = content_tag.get_attribute(\"innerHTML\")\n",
    "            content_html = re.sub(PATT_REMOVE_HTML_PART_TAG, \"\", content_html)  #消除除img以外的标签\n",
    "            content = re.sub(PATT_PARSE_IMG, replacement, content_html)\n",
    "\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content = \"\"\n",
    "\n",
    "        # https: // www.toutiao.com / a6794358241716339211 /\n",
    "    else:\n",
    "        None\n",
    "    return article_url, title, author, release_time, content\n",
    "\n",
    "def my_test():\n",
    "    \n",
    "    article_url, title, author, release_time, content = parse_article(\"https://www.toutiao.com/a6784351002280591876/\", browser)\n",
    "    print(content)\n",
    "    browser.close()\n",
    "    # print(download_img(\"https://p6-tt.byteimg.com/origin/pgc-image/d192ba55afe4411c805b97c5d4c127f0?from=pc\",'C:/Users/Administrator/Desktop/'+str(time.strftime(\"%Y-%m-%d %H.%M.%S\", time.localtime())) + \".png\"))\n",
    "\n",
    "\n",
    "def main(keyword):\n",
    "    Temp_Img_names = []\n",
    "    #获取相关文章url链接\n",
    "    print(\"\\n↓↓↓↓↓↓↓↓↓爬取文章url↓↓↓↓↓↓↓↓↓\\n\")\n",
    "    if len(article_dic_titel_url) == 0:\n",
    "        offset = 0\n",
    "        for i in tqdm(range(11)):   #首页列表中只有98条（只包括文章），包含视频有180条\n",
    "            parse_article_list(keyword, offset)\n",
    "            offset = offset + 20\n",
    "    try:\n",
    "        print(article_dic_titel_url)\n",
    "        browser = webdriver.Chrome()  # Get local session of Chrome\n",
    "        all_data = {}\n",
    "        all_data[\"url\"] = []\n",
    "        all_data[\"title\"] = []\n",
    "        all_data[\"author\"] = []\n",
    "        all_data[\"release_time\"] = []\n",
    "        all_data[\"content\"] = []\n",
    "        print(\"\\n↓↓↓↓↓↓↓↓↓爬取文章详情↓↓↓↓↓↓↓↓↓\\n\")\n",
    "        count = 0\n",
    "        for t, url in tqdm(article_dic_titel_url.items()):  #解析所有文章\n",
    "            article_url, title, author, release_time, content = parse_article(url, browser)\n",
    "            all_data[\"url\"].append(article_url)\n",
    "            all_data[\"title\"].append(title)\n",
    "            all_data[\"author\"].append(author)\n",
    "            all_data[\"release_time\"].append(release_time)\n",
    "            all_data[\"content\"].append(content)\n",
    "            if content != \"\":\n",
    "                count += 1\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df.to_csv(\"spider_data/\"+keyword+\"_\"+str(count)+\"条_articles_info_\"+str(time.strftime(\"%Y-%m-%d %H.%M.%S\", time.localtime()))+\".csv\")\n",
    "    except Exception:\n",
    "        print(\"保存失败\")\n",
    "        del_imgs()\n",
    "    finally:\n",
    "        browser.close()\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"无人船\")\n",
    "    # my_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import selenium\n",
    "import time\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_news():\n",
    "    data = {    #构造请求的data\n",
    "        'aid':'24',\n",
    "        'app_name':'web_search',\n",
    "        'offset':offset,\n",
    "        'format':'json',\n",
    "        'keyword':search_name,\n",
    "        'autoload':'true',\n",
    "        'count':'20',\n",
    "        'en_qc':'1',\n",
    "        'cur_tab': '1',\n",
    "        'from': 'search_tab',\n",
    "        'pd':'synthesis',\n",
    "        'timestamp': int(time.time()),\n",
    "        '_signature': '21oMXgAgEBAwjHnl59qFgNtbTUAAIWq5yRBJSZ83MdD56bgu5GDIJxHd0EHk8Y1-DDSzzYJ-ZlFlc5td8NE86Wb3wfbOIt2i-9L7pr2I3.bmY8SCimmZOjMIL2g7TKFO-Lj'\n",
    "    }\n",
    "    url = 'https://www.toutiao.com/api/search/content/?' + urlencode(data)\n",
    "    res = requests.get(url=url,headers=header)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadLine:\n",
    "    \"\"\"\n",
    "    topic\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.browser = selenium.webdriver.Chrome()\n",
    "        self.base_dir = '/User/vito/spider/'\n",
    "        \n",
    "    def get_page(self, topic:str, offset:int):\n",
    "        #通过decode工具得到data\n",
    "        params = {\n",
    "        'aid':'24',\n",
    "        'app_name':'web_search',\n",
    "        'offset':offset,\n",
    "        'format':'json',\n",
    "        'keyword':search_name,\n",
    "        'autoload':'true',\n",
    "        'count':'20',\n",
    "        'en_qc':'1',\n",
    "        'cur_tab': '1',\n",
    "        'from': 'search_tab',\n",
    "        'pd':'synthesis',\n",
    "        'timestamp': int(time.time()),\n",
    "        '_signature': 'IbFHAAAgEBA3yUF75cndAiGwBhAAH7IJXfv09r0xnfIHXUO.wGRyqhIENMKOMyAu3iCJztEo-qyssj6DE9odGsrrvM9bgxjb8OTCJCZ2keUE1waSz2iIaY7SpaNVulSvUp5'\n",
    "        }\n",
    "    url = 'https://www.toutiao.com/api/search/content/?'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params)\n",
    "        if response.status_code==200:\n",
    "            return response.json()\n",
    "    except requests.ConnectionError:\n",
    "        return None\n",
    "    \n",
    "    def __call__(self, topic:str):\n",
    "        data_dir = os.path.join(self.base_dir,topic)\n",
    "        if not os.path.isdiri(data_dir):\n",
    "            os.mkdir(data_dir)\n",
    "        offset = 0\n",
    "        url = get_url(self, topic, offset)\n",
    "        response = requests.get(url, header)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00, 35.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取热点文章链接\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 35.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import selenium\n",
    "\n",
    "browser = webdriver.Chrome()            # 创建浏览器对象\n",
    "browser.get('http://news.sina.com.cn/hotnews/')\n",
    "time.sleep(1)\n",
    "browser.find_element_by_xpath('//*[@id=\"Tab12\"]').click()\n",
    "article_list = browser.find_elements_by_xpath('//*[@id=\"Con12\"]/table/tbody/tr')\n",
    "\n",
    "titles = []\n",
    "contents = []\n",
    "content_href = []\n",
    "comment_href = []\n",
    "num_comments = []\n",
    "comments = []\n",
    "\n",
    "print(\"获取热点文章链接\")\n",
    "\n",
    "for i in tqdm(range(1,11)):\n",
    "    item = article_list[i].find_elements_by_tag_name('a')\n",
    "    content_href.append(item[0].get_attribute('href'))\n",
    "    titles.append(item[0].get_attribute('textContent'))\n",
    "    comment_href.append(item[1].get_attribute('href'))\n",
    "    num_comments.append(item[1].get_attribute('textContent'))\n",
    "\n",
    "def get_content(url):\n",
    "    # selenium 模拟\n",
    "    browser.get(url)\n",
    "    if 'ent' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"artibody\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "        \n",
    "    if 'finance' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"artibody\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "    if 'news' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"article\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "    news_content = ''.join([c.text for c in content_list if c.text is not None])\n",
    "    return news_content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:08<00:00,  6.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(content_href):\n",
    "    contents.append(get_content(url))\n",
    "    time.sleep(random.randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [02:13<20:01, 133.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [04:20<17:33, 131.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [06:24<15:05, 129.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [09:36<14:48, 148.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [10:26<09:52, 118.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [11:22<06:40, 100.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [12:24<04:25, 88.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [13:14<02:33, 77.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [15:18<01:30, 90.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:04<00:00, 96.42s/it]\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome() \n",
    "def get_comment(url):\n",
    "    # selenium 模拟\n",
    "    browser.get(url)\n",
    "    bottom = None\n",
    "    cnt = 0\n",
    "    while bottom is None and cnt < 100:\n",
    "        print(cnt)\n",
    "        cnt += 1\n",
    "        try:\n",
    "            bottom = browser.find_element_by_xpath(\"//*[text()='更多精彩评论>>']\")\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            bottom = None\n",
    "        time.sleep(1)\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # 等待刷新完毕\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        comment_list = browser.find_elements_by_class_name('txt')\n",
    "    except selenium.common.exceptions.NoSzuchElementException:\n",
    "        comment_list = []\n",
    "    comment_list = [c.text for c in comment_list if c.text is not None]\n",
    "    return comment_list\n",
    "for url in tqdm(comment_href):\n",
    "    comments.append(get_comment(url))\n",
    "    time.sleep(random.randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    # selenium 模拟\n",
    "    browser.get(url)\n",
    "    if 'ent' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"artibody\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "        \n",
    "    if 'finance' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"artibody\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "    if 'news' in url:\n",
    "        try:\n",
    "            content_list = browser.find_elements_by_xpath('//*[@id=\"article\"]/p')\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            content_list = []\n",
    "    news_content = ''.join([c.text for c in content_list if c.text is not None])\n",
    "    return news_content\n",
    "    \n",
    "def get_comment(url):\n",
    "    # selenium 模拟\n",
    "    browser.get(url)\n",
    "    bottom = None\n",
    "    while bottom is None:\n",
    "        try:\n",
    "            bottom = browser.find_element_by_xpath(\"//*[text()='更多精彩评论>>']\")\n",
    "        except selenium.common.exceptions.NoSuchElementException:\n",
    "            bottom = None\n",
    "        time.sleep(1)\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    try:\n",
    "        comment_list = browser.find_elements_by_class_name('txt')\n",
    "    except selenium.common.exceptions.NoSuchElementException:\n",
    "        comment_list = []\n",
    "    comment_list = [c.text for c in comment_list if c.text is not None]\n",
    "    return comment_list\n",
    "\n",
    "for url in tqdm(content_href):\n",
    "    contents.append(get_content(url))\n",
    "    time.sleep(random.randint(1,3))\n",
    "\n",
    "for url in tqdm(comment_href):\n",
    "    comments.append(get_comment(url)\n",
    "    break\n",
    "    time.sleep(random.randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'title': titles,\n",
    "        'content': contents,\n",
    "        'num_comments': num_comments}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comments)):\n",
    "    df = pd.DataFrame(comments[i])\n",
    "    df.to_csv(f'{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['到灾难来临之时，中国是做的最好的，为生在中国的我感觉到很安慰',\n",
       " '太严重了',\n",
       " '很明显这里的疫情比中国的武汉还要可怕十倍，根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离，不然意大利这个国家就彻底崩溃了。',\n",
       " '到灾难来临之时，中国是做的最好的，为生在中国的我感觉到很安慰',\n",
       " '太严重了',\n",
       " '很明显这里的疫情比中国的武汉还要可怕十倍，根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离，不然意大利这个国家就彻底崩溃了。',\n",
       " '根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离，不然意大利这个国家就彻底崩溃了；',\n",
       " '猥亵儿童真是罪大恶极，犯罪份子得到惩罚大快人心，法院判决合法合理，支持！',\n",
       " '严惩犯罪，保护儿童权益',\n",
       " '生命超越国际和肤色，希望这次疫情早一天结束。',\n",
       " '生命超越国际和肤色，希望这次疫情早一天结束。',\n",
       " '意大利新冠肺炎单日病死率是全球最高的，世卫组织和国际社会应该把意大利当成医疗援助的重点，发扬人类团结友爱，大量援助医生，护士和医疗设备，使意大利的新冠患者治愈率有很大提高，病死率大幅下降。',\n",
       " '生命超越国际和肤色，希望这次疫情早一天结束。',\n",
       " '累计确诊破5万',\n",
       " '相比之下觉得还是中国安全',\n",
       " '很明显这里的疫情比中国的武汉还要可怕十倍，根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离',\n",
       " '意大利加油',\n",
       " '意大利加油',\n",
       " '相比之下觉得还是中国安全',\n",
       " '很明显这里的疫情比中国的武汉还要可怕十倍，根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离',\n",
       " '意大利加油',\n",
       " '相比之下觉得还是中国安全',\n",
       " '意大利加油',\n",
       " '相比之下觉得还是中国安全，。、、',\n",
       " '累计确诊破5万',\n",
       " '累计确诊破5万',\n",
       " '处方1.警察负责（监督戴口罩，居民隔离等等。）2.军队负责（运输居民生活用品和医疗人员的医疗用品，生活用品。）3.政府负责（协调所有用品并有序分配。）4.医疗人员负责（按轻重分级病人，医治及安抚病人。）',\n",
       " '她已经死了',\n",
       " '这个',\n",
       " '他们医生的防护根本不彻底，怪不得许多医护染病和死亡，太不专业了',\n",
       " '天作孽，犹可恕……唉，可苦了我们的白衣战士...',\n",
       " '生命超越国际和肤色，希望这次疫情早一天结束。',\n",
       " '就他们这样自由的，50万都不稀奇',\n",
       " '意大利新冠肺炎单日病死率是全球最高的，世卫组织和国际社会应该把意大利当成医疗援助的重点，发扬人类团结友爱，大量援助医生，护士和医疗设备，使意大利的新冠患者治愈率有很大提高，病死率大幅下降。',\n",
       " '应该全力防止重症增加，积极为患者提供抗病毒治疗防止发展为重症',\n",
       " '笔误：“向中国输入” 应改成“向中国输出”。',\n",
       " '医护人员的防护服不够标准啊！易感',\n",
       " '要不我们给意大利捐点物资，再给点钱打发得了。让他们照着抄作业他们都不会啊，不中用啊。我们的医务人员去帮忙，好了还好。后面他们再大大爆发了，还说我们水平不够或没有尽心帮他们。',\n",
       " '意大利加油',\n",
       " '好的国家还需要正确的领导',\n",
       " '唉',\n",
       " '多向中国学习学习经验……',\n",
       " '好',\n",
       " '自由是有代价的',\n",
       " '意大利挺住！管住你们的腿，不给病毒传播的机会，你们会胜利的！',\n",
       " '集全国之力降低的死亡率',\n",
       " '意大利加油',\n",
       " '这让中国救援队怎么去救？  就是每天工作24小时一个月不休息  也没办法救得过来啊',\n",
       " '意大利太难了！',\n",
       " '但意大利将率先控制住',\n",
       " '我是你的铁杆粉丝。',\n",
       " '也请中国网友们，不要再看热闹，不要再调侃；意大利在死亡线挣扎不了多久了；中国发生疫情，就在我身边，我都没有这么悲观过！请允许我先哭一会，我很难过；',\n",
       " '意大利市民，我跪求你们 —— 隔离！隔离！隔离！',\n",
       " '以前我向意大利朋友推荐我的口罩被他拒绝了。',\n",
       " '',\n",
       " '很明显这里的疫情比中国的武汉还要可怕十倍，根本看不到拐点出现的希望；希望意大利人民，一定要坚守自我隔离，不然意大利这个国家就彻底崩溃了；想一想医务人员的处境，如果一线的医务人员，减员超过一半 ...... 现在看，这一切不可避免了；自私！会毁掉意大利的；战胜疫情！没有第二条路可走！看看意大利医护人员的防护级别，就是相当于裸奔！我预言，清明左右，意大利的医护人员会减员过半！是意大利人民自己\\n...展开全部',\n",
       " '太可怕了😱',\n",
       " '意大利的面积是多少？没印象了，',\n",
       " '国际疫情的严重性可能是我们迟迟不能开学的一个重要因素！愿别的国家拿出有力的防控措施象中国一样遏制疫情！',\n",
       " '身为吃瓜群众的我此刻能做的 力所能及的 就是找把椅子看戏 打分 丹麦 捷克你2得加油 人家美国就表现很好望继续努力 英国呢 小金毛干嘛呢 好好看看',\n",
       " '为意大利和全世界送上衷心的祝福！疫情无国界！抗疫需联手！',\n",
       " '随后就是美国，英国了。这就是自由散漫自我为中心的代价。',\n",
       " '恐怖',\n",
       " '意呆利太惨了，大有赶超当时武汉之势！',\n",
       " '为啥到现在这种状态医生还不穿防护服？',\n",
       " '让那个反对戴口罩的议员下岗，回家给民众缝制口罩，不是他的发飙故事，不让大家戴口罩，疫情就不会扩散这么快的。',\n",
       " '意大利加油啊！加油',\n",
       " '意大利，每天看着你新增的数字瑟瑟发抖，峰值快过去！',\n",
       " '估计这数据还有水分，但意大利现在也没什么可遮掩的，纯粹就是统计不过来了！现在意大利人还随便上街遛狗吗？',\n",
       " '不管怎么说，意大利人散漫不怕死的精神我还是有点佩服',\n",
       " '灾难面前意大利政府和中国专家组应该去拜会天主教教会，让他们出来说话，戴口罩是上帝的意思，呆在家里是上帝的意思，为你和他人健康必须呆在家里，别给政府添乱，疫情当前不戴口罩满街逛是要下地狱的',\n",
       " '现在的意大利，当务之急是建立大型方舱医院，把所有意甲联赛的球场都用上，把所有感染者集中隔离，让未感染者居家隔离，不切断传染源，局面更难以控制。',\n",
       " '哀其不幸。',\n",
       " '意大利，法国，德国……一定要挺住啊！\\n待疫情结束，你也该好好想想了，中国有句古话叫患难见真情，……记住是谁在危难的时候义无反顾不计恩怨的帮助了你！又是谁在你最需要救助的时候，冷漠的远远看着爱莫能助！长点心眼吧，不要再做米国人的小弟了，他们根本靠不住！',\n",
       " '要在重视程度上提高提高再提高',\n",
       " '意大利的数字很恐惧让人焦虑，不敢向呆在旋涡中心米兰的孩子问太多，怕加重他的心理负担，让他反而宽慰我们父母，不知道该如何去帮助他，最恐惧的心理煎熬就是怕他一旦染上，被救治的生机在哪呢？当地中国留学生很多，面临危险时该如何自救和被救？如果驻派一支医疗队就好了，不小心被患上至少有中国医生救助，',\n",
       " '意国迎高峰',\n",
       " '我想知道美国从意大利带走的50万支检测试剂到底是不是中国捐助意大利的物资',\n",
       " '有无相生阴阳：那是人家自己的，这种时候就不要想着搞矛盾了，这是全人类的灾难，麻烦你能尊重一下那些死难的人',\n",
       " '这样下去，确诊数量超过中国就是一周的事情',\n",
       " '看看如今的八国联军',\n",
       " '3月20日才封？早在干嘛？',\n",
       " '祈求天佑大地，意大利加油！！',\n",
       " '死亡率破9了',\n",
       " '措施太慢，人员还能出来捞',\n",
       " '意大利人民你们一定要注意啊',\n",
       " '好恐怖的',\n",
       " '自由的代价，意大利就是作死的',\n",
       " '我记得上学的时候地理老师说过意大利🇮🇹就是欧洲的脚和腿，意大利必须挺住，要不然欧洲真要倒下了',\n",
       " '人间惨剧，意大利只有自强自律才能拯救自己',\n",
       " '没有救了，意大利人自己启动了优胜劣汰的自然法则，可怜的老人们自求多福吧，阿门。',\n",
       " '过于自信惹的祸',\n",
       " '哎！我心痛！虽然是外国，但病毒死亡的都是无辜的人。心痛！！同时我更担心协助意大利的医护专家！辛苦了！',\n",
       " '不可能接管ICU，那得需要上万人，怎么可能，援助只能指导，哪能包办？国内是一省包一市，各省医疗力量都压力山大！',\n",
       " '意大利你能什么能，世界第一是美国不是你!',\n",
       " '这就是要自由的代价',\n",
       " '中国可以进行支持加大，哎',\n",
       " '这是真的。',\n",
       " '开岀药方你不用，自由散慢求乐道。新冠无情肆虐狂，无情带你入天堂！',\n",
       " '一定可以挺过去的 加油。',\n",
       " '太恐怖了！不拿新冠当回事，它肯定会把你当回事！',\n",
       " '意大利加油，挺住',\n",
       " '？',\n",
       " '疫情无国界，医护人员有国界。当初嘲讽我们的人，我都记得，我心里在看他们的笑话，但我不会说出来，我也可以说一些假货，呵呵',\n",
       " '意大利完蛋了，神仙也救不了，我们的专家回来吧。',\n",
       " '天佑意大利！',\n",
       " '哎',\n",
       " '这个速度太恐怖了😱这死亡率还这么高！',\n",
       " '小国又没有好的领导，没人救，可怜。',\n",
       " '必须禁足啦！',\n",
       " '希望快到拐点',\n",
       " '那个情绪激烈反对戴口罩的议员，现在可以起诉他个贻误疫情最，',\n",
       " '希望疫情尽快结束',\n",
       " '封的太晚了',\n",
       " '吧',\n",
       " '小国',\n",
       " '加油',\n",
       " '战疫情',\n",
       " '失去良机，成本翻倍。',\n",
       " '这就是没有做好防控体制',\n",
       " '还是百姓的防护认识差！',\n",
       " '疫情严重',\n",
       " '全球疫情蔓延，除了我们中国人民共产党员，人民警察还有我们的医护人员的全力以赴，还有人们潜意识的听党的号召力才取得了举世瞩目的成就，这是别的国家难以做到的！！！希望人们快点觉醒控制住疫情扩散，世界和平指日可待。“世界加油”',\n",
       " '控制不给力啊',\n",
       " '一个国家的正确举措，关系到每个国人的生死存亡。',\n",
       " '前段时间的武汉',\n",
       " '可怕',\n",
       " '上点心吧',\n",
       " '速度太快了',\n",
       " '意大利的封城原来只是个形式，难怪确诊不断增多。',\n",
       " '不知什么原因，国外很排斥戴口罩，最后结局就是很悲催。',\n",
       " '希望对其他国家有警示作用',\n",
       " '这两天开始往后都是爆发高峰，前期没控制住的结果。其实昨天前天都已经开始了',\n",
       " '咎由自取啊，我泱泱大国好心捐给你的物资，结果让美国拿走，享受后果吧。',\n",
       " '用不了一周时间，意义利确诊人数要超过中国，意大利引以为傲的医疗体系已无法救治这么多病人，好恐怖，希望意大利老老实实呆在家里，才会出现拐点。',\n",
       " '晚了，一切都晚了，意大利你们都很任性到现在你们还是不重视病情的传播。希望你们安好，',\n",
       " '看天下',\n",
       " '…',\n",
       " '防控隔离最重要，意大利加油！',\n",
       " '不少',\n",
       " '今夜无眠',\n",
       " '说只是大号流感仿佛发生在昨天',\n",
       " '人民只有人民才是才是人民的救世主！',\n",
       " '太吓人了，希望这个世界新冠早点结束',\n",
       " '唉',\n",
       " '意大利从上至下都没有真正引起重视，封城不封人，人就四处乱窜，好好学习中国吧，照抄书本都不会吗',\n",
       " '意大利你要加油啊，宅家别出门，别出门，别出门，重要的事情说三遍！',\n",
       " '教训多么深刻啊！',\n",
       " '老天保佑🙏疫情赶快从全世界结束',\n",
       " '他们是怎样确诊的，检测确诊速度这么快',\n",
       " '怎么办？控制不住 都是傲慢惹的祸',\n",
       " '抗击疫情不是每个国家的事，而是需要全世界各国人民共同努力的一件大事，未来全球各国需要在疫情抗击方面达到统一的意见，集中力量，彻底消灭病毒',\n",
       " '西方的世界观将会发生改变',\n",
       " '传染性很强',\n",
       " '意大利幡然悔悟，中国人民支持你们。',\n",
       " '加强疫情防控',\n",
       " '别看别人笑话了，把自己弄好最重要',\n",
       " '让疫情早点结束吧！',\n",
       " '尊重政府决定，尽快控制疫情发展，这次疫情真的很严重！必须充分认识，正确处理及时履责。',\n",
       " '措施来的太晚',\n",
       " '比我想象的严重',\n",
       " '按这速度发展下去，难以想象啊！',\n",
       " '这病毒太厉害了，不知为什么他们仍然有许多人不戴口罩',\n",
       " '封城？游行！',\n",
       " '无语',\n",
       " '关键是他们的医疗人员的自身防护没有做好！医护人员大量被感染，这样救护能力进一步减弱！有些镜头看出来就只戴口罩和护目镜，没有防护服和面罩，估计都做不到一次一换新的防护服。',\n",
       " '无论你的宗教信仰、政治制度和生活方式是什么，在病毒面前都得敬畏与尊重。',\n",
       " '医疗体系彻底烧穿',\n",
       " '为傲慢买单',\n",
       " '真恐怖，当时意大利人太大意了，不肯戴口罩现在爆发了希望在那的华人注意安全',\n",
       " '强烈要求撤回专家',\n",
       " '意大利大意了',\n",
       " '中国🇨🇳战胜疫情战术，西方国家就是不用，直到现在才知道关闭公园控制人群聚集，政府可能是先让大家看看新冠病毒厉害不，我剥夺大家的自由应该不应该，然后再采取措施，采取措施了大家才支持，这复出出的代价太大了吧。',\n",
       " '按意大利国家人口总数来说，这个比例真是太恐怖了，加油！！',\n",
       " '意大利🇮🇹真的是要挺住！',\n",
       " '说什么好！希望他们抗住，早日好起来！都是一个个生命！',\n",
       " '愿疫情早日结束！愿世界人民都平安吉祥！让那些嘲笑中国的人和把病毒带到中国的人去死吧！世界性大疫情的流行，没有谁能独善其身！',\n",
       " '意大利总人口多少啊',\n",
       " '.',\n",
       " '怎么这么多呀，传染太严重了吧',\n",
       " '欧盟其它国家为什么不帮助意大利呢？',\n",
       " '天，挺住意大利，早隔离，早发现，早治疗，早申报',\n",
       " '意大利医疗体系彻底崩溃了',\n",
       " '早上好',\n",
       " '意大利这次不死也要脱层皮了。',\n",
       " '严重的至暗时刻意大利人民挺住望平安',\n",
       " '意大利努力！',\n",
       " '不好控制！',\n",
       " '现在才体会到习大大说的人类命运共同体是什么含义！高瞻远瞩，心怀天下！',\n",
       " '既然封城就得封得住，封又封不住，还白白浪费了宝贵的公共资源。',\n",
       " '疫情严重！',\n",
       " '可怜那些无辜的生命，希望早点好转',\n",
       " '太快了',\n",
       " '意大利学美国不检测、不公布就无新增啦！',\n",
       " '医护感染太严重了，应该至少首先解决医护感染，否则这样下去医护不断减员，病人不断增加会彻底进入崩溃的，太惨烈了',\n",
       " '意大利到底是咋啦？',\n",
       " '为你祈祷🙏',\n",
       " '完全失控了，死了那么多人',\n",
       " '太严重了',\n",
       " '比当初的湖北的疫情厉害很多，加油吧！',\n",
       " '😓😓',\n",
       " '当务之急执行严格的防护和隔离是唯一的手段，盼望意大利疫情得到早日缓解和控制',\n",
       " '还在增长期',\n",
       " '太疯狂了！',\n",
       " '人道主义无国界，同情意大利人民！早点战胜病毒！',\n",
       " '哪里看到的新闻啊！我不反对派医护，但是中国必须提条件，意大利医院必须按照中国要求进行改造，成立联合战时指挥部，中方必须能说的上话，如果是抓壮丁似的派几个医护人员去，语言又不通，意大利防护又马虎，咱们的医护人员很难不被感染！',\n",
       " '🙏意大利快点好起来吧！',\n",
       " '死亡率到9%了。生命在呼吸之间，死亡面前再也不会有歧视和侮辱，再也不会将病毒标签化，我希望善良的人都能安然无恙（一定要安然无恙），别有居心的人都……（你猜）。',\n",
       " '哈哈我被我妈嘲笑，说我神经过敏，职业病',\n",
       " '疯狗咬人了，',\n",
       " '真的很担心我们的医疗援助队，希望他们平安，尽快归国',\n",
       " '你给爷爬',\n",
       " '不戴口罩还到处乱跑，傲慢自大，谁帮都没用',\n",
       " '一天增加六千多是真实数据，你品，你细品',\n",
       " '意大利是我特别想去看一看的国家 意大利菜是我最喜欢吃的西餐 希望军队介入后能有明显好转 保佑🙏',\n",
       " '不是要自由吗？让他们自由去吧，让我们的英雄医护们回来。',\n",
       " '能活过来的，会有后福的。',\n",
       " '中国没有义务中国没有义务中国没有义务',\n",
       " '国美比意大利严重，只是他们还没有检测点能力。。。',\n",
       " '现在觉得武汉的“应收尽收”太果断了',\n",
       " '这是人类共同的病毒 意大利加油吧',\n",
       " '要挺住一定要抗疫到底',\n",
       " '他们在这样下去就太可怕了，他们要自由可自由换来的是什么他们知道吗？无知的人做无知的事情，希望我们的医疗队不要上前线，可是如果能救人我们中国人不会见死不救的，这是我们中国人的最大的弱点，希望早日能控制住，希望平安🙏',\n",
       " '真替他们担忧呀，死亡率太高了，这就是不戴口罩的结局，不知道下一个爆发的国家是哪个。',\n",
       " '意大利加油，坚持住。',\n",
       " '哎 说点什么好呢，不听好人言吃亏在眼前啊',\n",
       " '病毒面前对于全球人类是一样的，你之前轻视它不做好防护，终究会给你惨通的教训。',\n",
       " '太傲慢了，而病毒感染无分贵贱 ',\n",
       " '失控了！撤底失控了',\n",
       " '确诊里也有善良的老人，无辜的小孩，希望你明白生命二字，中国拼尽全力减少损失，仍然也有悲壮的失去，人类的历史里没有任何人可以独善其身',\n",
       " '早就漰溃了',\n",
       " '我相信意大利没来及得急检测治疗死掉的也很多，它现在的医疗系统处于崩溃状态',\n",
       " '意大利也一样',\n",
       " '盲目自信的代价',\n",
       " '这是要勇夺第一？这第一可不光彩',\n",
       " '怎么回事啊！控制不住了啊！',\n",
       " '我们不是只去了专家吗？哪有医护队？',\n",
       " '天佑意大利🙏',\n",
       " '恐怖又绝望。快快好起来！🙏🙏🙏',\n",
       " '意大利挺住！！！国内严防境外输入！国内严防境外输入！国内严防境外输入！国内严防境外输入！国内严防境外输入！国内严防境外输入！',\n",
       " '其实，我们中国去支援意大利抗疫，一定要附加条件的：那就是意国一定要按中国的防疫措施严控新冠传播！否则，不应出征。',\n",
       " '感觉已经无力回天了，哎',\n",
       " '记得意大利要自由',\n",
       " '意大利加油，这个时候需要的是信心，一定能战胜病毒！同时严重鄙视那种幸灾乐祸，冷嘲热讽的人！',\n",
       " '阿弥陀佛',\n",
       " '这点，中日韩，就做的相当好。日本人平时就一直有戴口罩的文化',\n",
       " '胃口好大',\n",
       " '祈祷！！！',\n",
       " '赶紧让去意大利援助的中国人回来吧！那边已经失控了。',\n",
       " '估计他们都不会放人走啊',\n",
       " '中国的医护人员真的别去，不能网络指导吗，他们真把自己当根葱了，伸手要这要那，自己人都不穿防护服真的废。要别人献出力量还觉得应该的不会感激，这种人真服气了',\n",
       " '你以为他想报？   是瞒不住，得病的很大概率是重症，需要呼吸机得，没呼吸机就死',\n",
       " '西班牙 加油',\n",
       " '自私的希望，我们的白衣天使安全的早日回来',\n",
       " '意大利这速度是坐上了火箭🚀 啊',\n",
       " '·····单······身······好··········书········· 留到太晚，哥怎么能放心？”连耀辉很是坚持。“那行，哥，我先回家去！明天如果我有时间的话，我还来看你！当然，',\n",
       " '感觉比中国严重多了呀',\n",
       " '有道理',\n",
       " '咱们过去的专家团队人数也不足以支撑局面吧？希望他们都平安',\n",
       " '无辜吗？活该好吧',\n",
       " '第二个武汉',\n",
       " '让你们不戴口罩',\n",
       " '加油，意大利。',\n",
       " '每周10倍的指数增长',\n",
       " '不重视，他们医生防护标准低，还对我们物资挑三拣四',\n",
       " '一对比发现我们的医生做的太好了，我们是完全没有准备的情况下，对病毒完全不了解的情况下能把死亡率控制住，真的不容易',\n",
       " '外国人少是有理由的',\n",
       " '我只担心在哪里的华人',\n",
       " '太快了',\n",
       " '揪心啊',\n",
       " '你那么有爱心，你全家怎么不去当志愿者，恐怕你也就会在那里说风凉话吧，就像你这种畜牲言论，司马',\n",
       " '意大利 有点严重',\n",
       " '你这话说的，没人信还叫弄浑吗？合着大家都揣着明白装糊涂？另外你怎么知道层主不是揣着明白装糊涂呢？',\n",
       " '现在还在用这个头像的你们文宣部一天发多少钱啊，',\n",
       " '涩···········瑟·········箫········说········· 唐学谦被她笑得发毛，又不好发作，只能乖乖得被她笑。他现在彻底被人吃得死死的，凡是和乔语晨关系密切的人，他一概都不能得罪，',\n",
       " '是不是单日最大增幅还不好说啊……但这个数已经让我看懵了',\n",
       " '有方法吗？都是给你维持靠你自身抵抗力，能过来就过来过不来就过去，有没有解药',\n",
       " '也算是知错能改了',\n",
       " '现在不要再去说病毒来自哪里，这些事自有真相大白的一天，先救人。',\n",
       " '丫头说得好',\n",
       " '心疼意大利的医疗工作者',\n",
       " '西方国家发展绝对自由是对的，可以让他们醒醒，感悟下什么是最宝贵的，西方多少国家当初都感觉到中国的落后，资源的匮乏，有些过度紧张了，给他们争取时间他们缺不当回事，感觉压根就跟他们没丁点关系，现在他们知道了结果有多严重！',\n",
       " '唉，还没到高峰期，这是要赶超我们武汉的节奏，可悲的意大利',\n",
       " '美国🐶挺多',\n",
       " '。。。。一天这么多。这咋感觉像，之前就感染了现在来确诊的。',\n",
       " '担心我们的医疗队',\n",
       " '搞不好就是呆湾，越南来带节奏的...',\n",
       " '畜牲你说谁呢',\n",
       " '连迪巴拉和马队也中招了',\n",
       " '咱们中国医疗团队该有多无力啊！这失控了，杯水车薪，太可怕了！意大利要挺住啊！',\n",
       " '怎么你当时没给意大利人说呀',\n",
       " '底线底线底线底线底线，理中客理中客理中客理中客理中客',\n",
       " '意大利这么猛，吓人',\n",
       " '事实掌握在拳头啊',\n",
       " '别说非典，欧洲黑死病死了那么多人，欧洲国家吸取教训了吗？新冠开始时，我们是有些手忙脚乱，那是因为这是新病毒，一切都是摸索出来的，你先知先觉知道那病毒有多厉害？你现在看前面的措施也不过是事后诸葛亮。说得你比谁都聪明，那你去当领导好了！',\n",
       " '没有',\n",
       " '真是可悲.悔不当初疫情初发不重视；以至而今疫情蔓延无法控制！死亡民众为此疫情买单了！',\n",
       " '别跪着，键盘都跪裂了',\n",
       " '我已经不会了，这也太吓人了',\n",
       " '意大利全国才6000多万人，确诊5万多，全国发病率是0.09％，死亡率是9％。',\n",
       " '全程戴口罩，全程戴口罩，全程戴口罩。重要的事情说三遍，不听算了。',\n",
       " '老外对中国不了解，认为中国很落后，所以觉得疫情不可怕。感觉老外肯定不能像中国人那样自律，肯定不能自我隔离长达一个月之久。',\n",
       " '那我们留在意大利没有选择回国的学生 不是也被当人质了？',\n",
       " '坚决反对我们的医护去接管他们的ICU',\n",
       " '，',\n",
       " '😂',\n",
       " '那你去吧',\n",
       " '病毒真是不识好歹啊！咋这么不待见自由呢？难道病毒也有自由？',\n",
       " '换位思考吗，2009N1H1起源于美国的，全球20多万死亡。',\n",
       " '加油意大利！',\n",
       " '不听话的结果！',\n",
       " '前段时间有个新闻说只有确诊了才会戴口罩是哪个国家来着？还有我国留学生在海外戴口罩被嘲笑',\n",
       " '祈祷意大利赶紧好起来，世界好起来',\n",
       " '看到你们骂他我就放心了，舔你妹呢？',\n",
       " '意大利情况太糟了',\n",
       " '这是任性的代价吗',\n",
       " '我看了一个视频，意大利的人还在街上乱跑，都没戴口罩。',\n",
       " '希望意大利好起来 一起加油',\n",
       " '也未必都是老人',\n",
       " '希望早日能战胜病毒',\n",
       " '假如武汉封城晚5天，就应了钟院士的预测！意大利加油！',\n",
       " '回复 @第五个季节睡眠:看那个照片我就很崩溃，意大利医护不穿防护服只戴口罩，万一传染了不是要把中国的医护传染吗',\n",
       " '疫情严重！在人类共同灾难面前每个人都会深受其害！幸灾乐祸的人不是坏就是脑残！',\n",
       " '神经病',\n",
       " '自己作的，没办法到现在满大街还是人呢，怪谁',\n",
       " '意大利你做个人吧。戴口罩好吗？不要自由了好吗？居家呆两个月好吗？我们医护人员是给你提供建设性意见的，不是去给你拼命的，有要求向欧盟和世卫提去。',\n",
       " '讲真，现在病毒的源头也没找到，合理怀疑，不可以吗？',\n",
       " '嗨········闻·········书············刊········ 懂得退让的男人最可怕，他们不疾不徐，站在背后为你撑起整个世界却不求回报，随着时间流逝，你会觉得把整个人生都欠给了他。',\n",
       " '头铁的代价，神仙难救',\n",
       " '严重',\n",
       " '中国这么好的例子在前面。国家和国民都不引起重视。',\n",
       " '美国🇺🇸，靠，自救都不愿意，还会支持他国吗？',\n",
       " '有什么b脸要我们的医护人员 贱不贱啊',\n",
       " '防控积极排查到位，病例自然会增加，瞒报的甚至根本不查的，普通老百姓中发生的实际病例并不少。比如美国人，掩盖疫情真相对人类社会危害更大。',\n",
       " '帮你是情分',\n",
       " '这个时候了，经济什么的都必须要放下，要拨款全力支援医疗抗疫了啊，要赶紧把防护设备增加，否则医生全倒下，就真灭国了，意大利人缘也不咋滴呀，采购的医疗医护用品也被多国截糊！难道天要亡意？真希望他们能赶紧控制住疫情，不要再死人了，中国的医疗队也要注意啊，千万别进Icu，在旁指导就行了，虽然只有中国支援意大利，那也不是中国就该必须支援你们的，那是出于道义支援意大利，希望意方能保护好中国支援队的每一名医生！',\n",
       " '已经失控',\n",
       " '希望你们平安，中国也是。',\n",
       " '中国医疗队一定要确保自身安全啊！🙏🙏🙏',\n",
       " '我们到处乱跑了吗？自从1月22日全国开始重视后，我们这边街上10分钟看不到一辆车，反正我们这边的人挺有素质的，不知道你们那边喽。',\n",
       " '神仙难救',\n",
       " '昨天才封娱乐场所什么的吗？',\n",
       " '我靠 喜欢的球员全部确诊 是不是接下来要轮到我了',\n",
       " '加强防疫',\n",
       " '老龄化日本第一他第二',\n",
       " '希望意大利能早点控制疫情、让人民过上安定的生活。',\n",
       " '震惊，恐怖',\n",
       " '9%的死亡率，太恐怖了。',\n",
       " '给他点赞，让他知道口无遮拦带来的教训',\n",
       " '让我们的医疗队早点回来',\n",
       " '看看看看',\n",
       " '傲慢的结果',\n",
       " '希望全世界的疫情赶快过去，一切都回到原来的样子',\n",
       " '这就是要求自由的代价！',\n",
       " '他们封城，照样可以在城里走动，喝咖啡，聚餐，我们封是连小区都封起来了，买菜都有专门的人来送，垃圾放门口，家门不给出，全都困在家里做饭，看电视，武汉到现在还是这样的',\n",
       " '希望如此',\n",
       " '嗯ヽ(○^㉨^)ﾉ♪',\n",
       " '没准是故意放任不管的',\n",
       " '照这速度 意大利将成为世界第二移民大国',\n",
       " '从3月21日起才关闭的公园和公共场所吗？？？什么操作，都这样了大家还在遛弯吗',\n",
       " '人民的确是无辜的，但也是不愿意配合管控，属于自找的，不是不同情，是一旦被感染，就目前的医疗状态，你已经没有机会被同情惊醒了。',\n",
       " '疫情严重，积极面对做好救治防控吧！',\n",
       " '你知道什么叫变异吗？毒株都不一样！或许传到中国时就开始变异了！不懂就别尬洗，舔美🐶biss',\n",
       " '西班牙百年冤情都真相大白 沉冤得雪啦  是谁的错必须得人 生命啊兄弟',\n",
       " '到底是怎么了？',\n",
       " '怎么办呢',\n",
       " '谁又有证据证明病毒是从中国起源的呢？现有证据只能说明中国是第一个吹哨的，也是第一个控制住的',\n",
       " '你赶紧第一个报名啊，这么无私怎么舍得让别人上呢？必须身先士卒，是男人却不能说自己不行哦',\n",
       " '有着你这种想法的人，可以去当志愿者。不过武汉的志愿者都没有当，就不要在这里说大话了。',\n",
       " '我要缓一缓🙏',\n",
       " '同情意大利人民，希望疫情快点过去。',\n",
       " '全球支援，共同抗疫，没有谁能独善其身。',\n",
       " '不要幸灾乐祸啦，真心同情他们，现在应该呼吁更多不严重的国家出动医疗人员帮助意大利渡过难关，感觉他们的医疗系统要奔溃了，心疼那些人',\n",
       " '这是他们自己选择的命运怪不得别人',\n",
       " '因为，畜牲东西是你啊。',\n",
       " '说实话，我希望这个数字是美国的',\n",
       " '...........火............热...............嗨...........芠..... “是赤时公司新人不破尚的新单曲要拍PV，所以我就顺便帮你报了个名。不过如果你实在是不想去的话，那也没办法。”',\n",
       " '这增长的也太快了，什么时候能出现拐点降下来啊！这死亡的也太多了！',\n",
       " '氵显、、、、、、、、、钕、、、、、、、、、爽、、、、、、、、、文、、、、、、、、、 岑风边走边抬手朝她们竖了下大拇指。快把几个粉丝乐疯了。哥哥夸我们了',\n",
       " '呵呵！理中客来了。',\n",
       " '这就是未来的英国吧。。。',\n",
       " '我们现在派的医疗队是干嘛的。',\n",
       " '【迪巴拉、马尔蒂尼确诊】  累计确诊破5万，其中包括了迪巴拉和其女友，以及马尔蒂尼父子。迪巴拉本人在社交平台确认，他和女朋友Oriana都感染了新冠病毒，幸运的是现在情况良好。稍晚时候，米兰官方宣布，保罗·马尔蒂尼和其儿子丹尼尔同样确诊感染新冠病毒🙏🏻 ',\n",
       " '这不行，完全不行，派咱的人接管就是父母看着自己孩子往火坑里跳，谁舍得',\n",
       " '嗡嘛呢呗美哄 舍🙏🙏🙏',\n",
       " '病死率啥时候降，那么病情就控制下来了，轻症统一隔离他们做了吗？',\n",
       " '太惨了 🙏🙏',\n",
       " '它什么人脸那么大值得我们倾囊相助。斗米恩，升米仇',\n",
       " '美国是大佬脾气',\n",
       " '太恐怖',\n",
       " '怎么现在都这么自我膨胀，真的以为中国能救全世界？别的国家一无是处？',\n",
       " '管理越乱，传播越快。',\n",
       " '人间悲剧，一条条鲜活的生命，多少个家庭支离破碎，天主啊，保佑意大利人民吧',\n",
       " '你是不是住进我心里了',\n",
       " '如果你连我这段话都读不懂，那就不用和我讨论了',\n",
       " '意大利需要加上管控啊，老龄化太严重。',\n",
       " '医疗系统接近崩溃了',\n",
       " '······情······涩··············文.... 他一直都是清冷的，所以她在和他的爱情道路上已经做好了持久战的准备。不管是30、40、还是50岁，她都会等他开口。',\n",
       " '这条件也太差了吧?',\n",
       " '说的好',\n",
       " '快快好起来，意大利加油',\n",
       " '人们啊！千万别出门啊！',\n",
       " '🙏🙏🙏',\n",
       " '病毒可能是从MG那传出来的，但应该不会是投毒吧。投毒等于宣战了，就现在我觉得他还没能力直接向咱们宣战。何况MG要大选了吧',\n",
       " '好担心我们的医务人员，多想一下要流泪！',\n",
       " '传染的管控不利，只靠医疗是不行的！',\n",
       " '这个数据应该还要扩大',\n",
       " '该。面对如此可怕病毒。还无所谓吗？还聚集吗还要跑步吗还干吗干吗吗都该死',\n",
       " '新冠病毒唯一优点就是公平，每个国家都跑不掉，你尊重它，它就远离你，你瞧不起它，它就发脾气。',\n",
       " '要GG，和希腊肩并肩的节奏',\n",
       " '对，医疗团队给予指导就好了，不能一直留在那里',\n",
       " '你说的同情心和同理心都没错，但你说牲畜就过分了啊',\n",
       " '看了你的微博，你不过是个反中分子！',\n",
       " '意大利加油哦💪',\n",
       " '可怜的意大利人',\n",
       " '其他国家都一样的，不撞南墙不回头。等大家都明白病毒的厉害就都戴口罩也不聚会了。',\n",
       " '几百个也不行，它什么人脸那么大值得我们倾囊相助。斗米恩，升米仇',\n",
       " '这层楼里面的精神美国人快气死了，我只觉得人在做天在看，天道自有轮回。',\n",
       " '四川已经过去一批华西的医生了',\n",
       " '这么优秀吗',\n",
       " '医疗资源跟不上，死亡率会越来越高。这个病如果不上呼吸机很多人是挺不过来的。',\n",
       " '幸灾乐祸 和 不幸灾乐祸，都影响不了别人，更改变不了疫情的趋势，所以，你管别人幸不幸灾乐祸干啥',\n",
       " '300多医护人员，而且是分批过去',\n",
       " '卧槽，真的是可怕',\n",
       " '太可怕了呆利坚持住坚持住，希望拐点马上到',\n",
       " '意大利加油！',\n",
       " '没法接icu 言语不通怎么接，可以做些指导性的事情，但是人家民众又不听劝，这可真是麻烦',\n",
       " '阿弥陀佛🙏',\n",
       " '事实说明，中国的疫情致死率是在有效救治下才能达到的最低值，而国外没有有效治疗的情况下，致死率很可怕。',\n",
       " '这段话整的有问题，到底有没有关系？l一会难辞其咎，一会不认同的。自己都搞不懂有没有关系了？',\n",
       " '港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺港肺 港肺港肺港肺港肺 经鉴定！',\n",
       " '英文開頭，數字結尾',\n",
       " '当时嘲笑我们最狠的，也是现在爆发数量最猛的！这就叫做风水轮流转，当时最会装的美国，现在也最会装，我就不相信他只有1万多',\n",
       " '急了？',\n",
       " '加拿大华人现在还在因为戴口罩逛超市而遭驱逐',\n",
       " '意大利加油！',\n",
       " '已經說了',\n",
       " '没有必要',\n",
       " '武汉湖北是同胞，都是炎黄子孙，豁出命去救援。  对于管控不利、民众配合不好的意大利不至于玩命去救援。',\n",
       " '脸打的可真疼',\n",
       " '太难了',\n",
       " '经过这次疫情后中国将被重新认识',\n",
       " '灭国?',\n",
       " '我还记得当年希腊在报纸登广告卖小岛，好像是21世纪经济报道。呵呵，也是为了利罢了，内心不认同你。不过无所谓，强大了你硬挤笑脸也得端着。',\n",
       " '意大利是全球超过中国勇夺第一可能性最大的国家',\n",
       " '意大利那么歧视中国人，即使你给它捐物资捐钱，派医疗队，甚至上ICU，哪怕是牺牲！意大利是不可能领情的。人家觉得这是你们中国传播过来的，他们自认为发达，眼里全是傲慢歧视！中国的医疗队绝不能给他们卖命。',\n",
       " '疫情赶快过去！🙏都是鲜活的生命啊～',\n",
       " '小人夸得志,君子思归欤',\n",
       " '看他的主页并没有，只谴责中国',\n",
       " '赶紧把药给支援过去吧！不然比这更多',\n",
       " '你是在说丹麦还是在说美国欧洲的种族主义者？',\n",
       " '怎么搞得',\n",
       " '看见躺着的，再看看他们的医生防护做的都不好，悲催。﹏。',\n",
       " '3.4的死亡率怎么来的',\n",
       " '天哪，快快好起来',\n",
       " '他怎么样了现在',\n",
       " '祈祷🙏🏻 希望他们能够战胜',\n",
       " '没有证据不要乱说只能说大概率是的，米国人坏的很',\n",
       " '哎，怎么每天这么多，啥时候能降下来啊',\n",
       " '太恐怖了，当初对疫情的认识太浅薄。导致疫情如此糟糕泛滥成灾。真心的祝福意大利🙏🙏🙏期望一切都好起来。',\n",
       " '自由散漫害人不浅啊',\n",
       " '意大利优化国人的方法。',\n",
       " '我都快忘了这大鄂了',\n",
       " '把我们的专家赶紧撤回来吧，太危险了，意大利人自己不做好防护，即就是全世界支援有啥用。',\n",
       " '孤枕难眠 我爱这个世界',\n",
       " '我想知道里皮他老人家身体怎么样？',\n",
       " '发达国家好像都和科学不沾边，我们老百姓的觉悟都比她高',\n",
       " '完犊子了',\n",
       " '不带口罩是控制不住的',\n",
       " '正解',\n",
       " '发一条几毛钱啊',\n",
       " '我真纳闷  意大利6000万人口怎么比中国14亿死亡病例还多呢？',\n",
       " '不比不知道，我们的国家真伟大！',\n",
       " '不重视的结果',\n",
       " '可怜之人必有可恨之处',\n",
       " '到现在很多意大利人还不重视，还不戴口罩，医护人员的防护做的也不好，真不知道他们怎么想的',\n",
       " '人家侵略你，恶心你，讽刺你，玩弄你的时候从来不会有同情心和同理心，儒家思想真的毒害千年',\n",
       " '已经没救了，太恐怖了！心疼医护人员！',\n",
       " '那没事了',\n",
       " '世界第一把交椅有大国风范,，中国',\n",
       " '意大利加油',\n",
       " '我们回复你的都是你的父母，所以你是什么？',\n",
       " '好优美的中国话！',\n",
       " '好难过',\n",
       " '惨也是他们自己作的，现在还想我们中国出物资，出医护人员 简直是有点可笑了',\n",
       " '不要出门了，大家要自觉隔离I4天，这样可能慢慢好起来，否则你们会失去更多的亲人',\n",
       " '这个是应查尽查应收尽收了吗，如果是的话说明还是有希望的',\n",
       " '完了，怎么办？意大利🇮🇹太恐怖了！6000多，出不了气呢！需要援助！',\n",
       " '人家200名医护还要求放假呢',\n",
       " '希望保护好我们的国家团队！',\n",
       " '低估别人的能力。导致今天结果',\n",
       " '那你祖宗十八代都有脚气？',\n",
       " '中国人救中国人，凭什么还要去救意大利人？',\n",
       " '千万不能接，都希望你们能安全回来',\n",
       " '医疗系统崩溃了',\n",
       " '已经好多人开始这么说了',\n",
       " '怎么比武汉还严重',\n",
       " '希望意大利不要赶超中国，毕竟那是一条条鲜活的生命啊但是照这个发展速度，不想赶超真的太难了！',\n",
       " '放炮不听话了',\n",
       " '请问，是什么最新研究，哪些专家学者在哪个期刊上发表的研究成果？我只记得台湾的节目说日本电视台说的，可是我不信任“茶叶蛋”的台湾大嘴媒体，该节目也没说清楚日本哪位专家学者的研究。您在张口就来“根据最新研究”的时候，请问您有没有亲眼去看看那篇研究报告？最基本的，名称是什么，作者是谁？',\n",
       " '哈哈哈哈哈哈哈😂',\n",
       " '军管吧，已经完全是崩溃了',\n",
       " '意大利无法承受之痛！',\n",
       " '意大利人心惶惶了吧',\n",
       " '再有几天就超过我国了',\n",
       " '挺住',\n",
       " '第二，关于支援意大利，国人理解是救援，他们理解是我们制造了病毒，过去赎罪的；',\n",
       " '即然去了、就没有退路 维有全力以赴共克时坚虽子不翘 救死扶伤乃医护之神圣天职！我之中华儿女铁骨铮铮其志之坚刚其情也真切鬼神莫泣．唯愿诸君切记！早日平安凯旋而归…未来可期……我等在此静候佳音……生当百姓敬仰 死亿万民供奉 吾之白依天使加油万事珍重 ！',\n",
       " '打雷的时候得离你远点',\n",
       " '唉 说话太恶毒了',\n",
       " 'nmgcb',\n",
       " '🙏🙏🙏',\n",
       " '脸都给她打没了',\n",
       " '止不住了',\n",
       " '天作孽，由可活！自作孽，不可活！',\n",
       " '意大利加油！',\n",
       " '哈',\n",
       " '我就不怼你了..咱们讲道理，汶川地震，不会威胁救援队，这次意大利巴比伦是个巨坑，四川、浙江的专家万一...你能接受吗？',\n",
       " '恐怖的数字！ 回想一月份，武汉封城、全国动员的决策多么正确！',\n",
       " '网上还有意大利居民出门遛狗，遛玩具狗，依然不当回事儿',\n",
       " '意大利🇮🇹，你们要挺住。要想活命就在家待着。死死的憋着。别出去乱走。这就是对家人的关心。就是对祖国的省心。要像中国🇨🇳学习。别到处玩了。在家待着，体验一下提前退休的感觉。加油加油加油。',\n",
       " '傲慢与偏见害死了他们，希望疫情过后西方国家能够对我们改变观念。',\n",
       " '政府不作为的结果',\n",
       " '当初欧美也嘲笑我们的',\n",
       " '日新增确诊奔万、死亡奔千的节奏，病毒血洗意大利🇮🇹 。。。',\n",
       " '你快点滚出中国，永远不要回来。🍌',\n",
       " '中国派过去的医疗队一定要保证安全啊',\n",
       " '中国医生🇨🇳！我们的家人你们尽力了，快回来吧！这不是你们能控制住的，不要再搭上你们性命。',\n",
       " '彻底失控了 那么小的国家该怎么负担',\n",
       " '现在这种状况，中国医疗队撤不回来吧，心疼中国医疗队，杯水车薪。意大利医疗资源崩塌，不能举国之力并有效抗疫情。感觉他们抄作业抄得太不严谨了。',\n",
       " '表达下沉痛吧。',\n",
       " '嗯老嬷嬷',\n",
       " '这不是幸灾乐祸，这是在反思。',\n",
       " '然而那不勒斯人还在大街上不带口罩游玩',\n",
       " '天佑意大利',\n",
       " '天真，外国人会让中国人指挥？',\n",
       " '灾难啊！祝福意大利🇮🇹',\n",
       " '现在这情况就相当，1000人中间就一个了',\n",
       " '这才第一轮的十四天啊，拐点还早呢，什么时候是个头呀，祈祷全球疫情早点结束吧',\n",
       " '现在能不能撤回医疗队，真的担心',\n",
       " '你这么能干你们全家去么。',\n",
       " '希望他们也能像中国一样早点儿控制住疫情！',\n",
       " '这下总算打醒那些所谓要自由不要命的西方家伙们了',\n",
       " '中国疫情爆发的时候，中国华侨把意大利所有口罩都买光了，都寄中国了，意大利爆发了，议员带了，再让市民戴口罩，市民恐慌抢购的话，医护人员就很容易空缺',\n",
       " '麻烦先站起来再说话可好，垃圾',\n",
       " '自信点，把“吗？”去掉',\n",
       " '现在能救意大利的除了中国只有意大利自己',\n",
       " '有没有跟我一样被春雷吵醒的',\n",
       " '她还和咱们四川援助队伍握手了的',\n",
       " '我的妈呀',\n",
       " '不愿意戴口罩，不严格隔离，后果来了',\n",
       " '太恶心了他们',\n",
       " '好可怜',\n",
       " '你说的就是全中国百姓要说的，太中肯了！',\n",
       " '每一片雪花都有重量',\n",
       " '不管怎样，还是希望尽快战胜病毒，快点好起来',\n",
       " '锁国中，回不回得来是个问题呢。我国的医疗队一定要挺住啊',\n",
       " '对，目前发病的人，按14天的时间推，3月初感染的，这批人可以说是不知道病毒的厉害，从现在这段时间往后的发病的，就是咎由自取，我很早就关注意大利了，我们在过年期时，他们在橘子大战，然后嘲讽我们！说中国人吃活老鼠，我们去帮助他们是在赎罪！！只会是农夫与蛇的故事！',\n",
       " '希望意大利快快控制住！紧急需要国际支援！',\n",
       " '哎！要是早点觉醒开始防范，何以至此！',\n",
       " '他那是黄鼠狼给鸡拜年就没安啥好心，中国人的事中国人自己研究，不需要一群畜牲发表意见，他们都是一群数典忘祖的🐶，不配称人，更不配称中国人',\n",
       " '这还怎么整，大罗神仙也救不了啊。。。',\n",
       " '你，可以听懂话吗？我再说一遍，意大利官方有表示疫情爆发可能和武汉无关，我国官方也公开对病毒起源表示怀疑，如果没有确凿的证据是不会这样说的。如果你说我们国家全面爆发武汉官方难辞其咎我认同，但是你非要把意大利的锅甩给武汉是不对的。',\n",
       " '帮情谊到了就好了，希望国家别迂腐了',\n",
       " '我的天啊！好恐怖啊！希望尽快有好转！祈祷🙏',\n",
       " '我说的余震可能性很低，传染病百发百中',\n",
       " '哪里看到20号去了300人',\n",
       " '美国目前都没有让世界卫生组织专家去调查美国流感，肯定是心里有鬼',\n",
       " '八国联军侵华忘了？',\n",
       " '怎么没看到有谁求助美国的报道？有没有？',\n",
       " '这是传染病，随时都会死，地震又不会死',\n",
       " '可怜之人必有可恨之处',\n",
       " '人民币付款',\n",
       " '看来意大利国内怎么宣传都没有用啊，何时是个头呀',\n",
       " '这死亡率真高，说明还有很多带确诊的。唉，疫情早点过去吧',\n",
       " '愿我们的逆行天使能平安归来',\n",
       " '🙏',\n",
       " '回复 @早起加蜂蜜水:站着说话不腰疼，又不是你去送死',\n",
       " '太难了，我们真的尽力了，说到底这是他们国家自己的事，让他们自己解决',\n",
       " '无知和愚昧才会发展到现在这个样子！教训深刻！',\n",
       " '禁止这禁止那，同时要在宣传科普上增加力度，只有让每个人重视警醒起来，自觉维护公共卫生安全，才是最好的全民总动员。思想观念的不作为，才是行动上的症结所在。意大利加油！',\n",
       " '你觉得会说出来？',\n",
       " '做梦吧',\n",
       " '好严重 到后面会不会像中国求助要医疗队呢 如果医疗队去了会不会安全 控制不住了会不会被绑架要挟 比较外国人很狡猾',\n",
       " '我们国家从来都是自給自足，自己人帮自己，其他国家都是嘲笑别人或者冷眼旁观，暗自窃喜罢了，人道主义上捐捐物资也ok了，我们国家还是太善良了常常上演农夫与蛇的故事',\n",
       " '这次疫情就像照妖镜出了这么多了，你也想来当一个？',\n",
       " '口出狂言者必招报应',\n",
       " '意大利自己都承认实际死亡人数是公布的五倍 很多还没检查就死了，好真实数据呢',\n",
       " '总有一些人觉得自己高贵典雅',\n",
       " '疫情过后，西方又会变回原来的嘴脸，根本不记我们的好',\n",
       " '为意大利🇮🇹祈祷！',\n",
       " '他自己就是个畜牲，他还舔个逼脸说别人',\n",
       " '意大利🇮🇹挺住啊！不要再到处走了，在家待著、待著、待著⋯，保护自己也保护你的国呀～',\n",
       " '你去接icu',\n",
       " '🙏🙏🙏',\n",
       " '意你不要笑话任何啊，老天都看在眼里的，自有度量',\n",
       " '这下完蛋了',\n",
       " '自己作的',\n",
       " '这是开始不重视的结果',\n",
       " '要是国家像你着度量小家子气早就完了，世界不好中国也好不了',\n",
       " '我看伊朗就比意大利好，伊朗病例数字虽然也不少，起码还比较稳定稳定，没有进一步扩大，意大利是成几何级往上涨，太恐怖了|',\n",
       " '坚决不能接管，到时候有事情就是我们中国背锅',\n",
       " '一群香蕉人',\n",
       " '别这么说，别这么误导好嘛？我们国家从来不想侵占他国，我国从来不是好战份子',\n",
       " '想当初世卫的人都没有直接去武汉或是湖北的，来了广东等其他省',\n",
       " '很高了',\n",
       " '天啊😱',\n",
       " '我真的觉得他们脑子跟正常人不一样',\n",
       " '自由的代价，是该严格控制的时候了',\n",
       " '数据透明不好吗，别双标',\n",
       " '意大利这种情况，会不会已经发生了居家传染，就像是武汉前期一样，居家隔离的已经把家人传染了，他们还没有大规模的建方舱，很可能已经一家一家的传染了，他们大街上戴口罩的人都很少，更何况是家里呢，病人把家人也传染了',\n",
       " '我们也只是发展中国家，意大利值得我们去拼命？',\n",
       " '口罩口罩口罩，赶紧听话带口罩啊，看着真着急',\n",
       " '放你的狗屁 你怎么不去',\n",
       " '他们现在有口罩可用吗',\n",
       " '意大利要挺住啊！',\n",
       " '脸真大，全面接手，醉了',\n",
       " '他们国家的事说到底还得他们自己解决，我们真的尽力了',\n",
       " '可能觉得你说的很对吧   各相关微博下留一波',\n",
       " '卧槽！防护服都不买……',\n",
       " '意大利快醒醒，不想看到你团灭，世界少了你就不完美了',\n",
       " '不居家隔离，你们是，白治疗，必须控制流动人口，',\n",
       " '这是传染病，我们的医护后期都是三班倒，因为人数够，接管了意大利根本没人，累死也管不了。巧妇难为无米之炊。圣母也得分时候。',\n",
       " '意大利的0号病人去的夏威夷',\n",
       " '不同意接icu，太难了',\n",
       " '你是这两年平时不看时事政治新闻，这两年欧盟国家也就意大利和希腊是挺我们的，也和欧盟这两个国家快要破产有关，但他们两个国家这两年一直和其他欧美国家唱反调站中国也是真的',\n",
       " '意大利人民加油❤',\n",
       " '估计删了，没看到她说啥了，害得我故意翻看微博，一看就是海外号带节奏那种',\n",
       " '也是，搭理这帮没有大脑的狗干嘛，反正咱们现在能吃吃喝喝生活正常',\n",
       " '希望全世界早日战胜病毒，全人类都平平安安！',\n",
       " '你别忘了别国是怎么对我们的，你才是畜牲',\n",
       " '除了中国，没有人会帮，但意大利又不是中国，帮也很难',\n",
       " '全民免疫，呵呵',\n",
       " '道德帝？',\n",
       " '🍓深...........夜...................读..................物.🍓................、 这三十万的手术费，连同那纸契约，就像压在她胸口的一块大石，时时压得她喘不过气来，并且时时刻刻提醒她，现在她是风泽的人。',\n",
       " '想想自己为啥被别人骂这么惨',\n",
       " '事情发展到今天，换位思考你会怎么想，疫情发展至此，武汉官方难辞其咎',\n",
       " '恐怖',\n",
       " '我们的医疗队，为了国家依然逆风而行，该适可而止啦！！为他们的家人想想吧！他们人在他乡，他们的家人也该是渡日如年，愿我们的天使安好，早日凯旋归来，加油！！',\n",
       " '为什么美国没有报道，是不是有解药，',\n",
       " '太快了',\n",
       " '堪比战争伤亡',\n",
       " '咻涩……………澀^^^^^^^煌^^^^^^^书^^^^集^^^…………………… 当然，除了偶尔脾气不好，性格霸道，然后占有欲十足这些缺点之外，他已经算是男人中的战斗机和精品！',\n",
       " '为意大利人民祈福，希望早点结束疫情',\n",
       " '大部分都是担心我们的医护人员，不然关我们什么事。',\n",
       " '这么涨下去是要崩溃的节奏',\n",
       " '无知者无畏啊！',\n",
       " '加油',\n",
       " '现在武汉还在治疗的重症患者，也够愀心的。这么久前景堪忧，不容乐观',\n",
       " '是不是从现在开始，奢侈品和豪车都不能买了',\n",
       " '意大利这种情况，仅中国专家指导已经是杯水车薪了，意大利申请人道主义援助吧!否则只能等人死完，情况太糟糕了!',\n",
       " '那女的就是意大利版的王广发，可防可控让意大利民众不要恐慌的就是她',\n",
       " '你们的无知愚蠢让多少人无辜受累，中国开卷让你们抄你们都抄不及格',\n",
       " '看你必将的微笑脸我想绝你就',\n",
       " '死亡率有点太吓人了',\n",
       " '来  继续不带口罩',\n",
       " '反正现在已经派很多中国医生去了',\n",
       " '这是场血的教训，防护意识为零的酣睡者！该醒醒了！',\n",
       " '天主教就是基督教？',\n",
       " '不能道德绑架，不同意接管ICU!',\n",
       " '恐怖！',\n",
       " '非典已经过去十多年了，但当初的教训从来就没有以史为鉴',\n",
       " '意大利快好起来吧！加油',\n",
       " '指导专家组就行，一线不可能去，对自己有什么好处，没必要为别人拼命，天知道那些要死的病人会做出什么样疯狂的举动',\n",
       " '🙏🙏🙏',\n",
       " '派的已经是最优秀的专家过去帮忙了，还得寸进尺，不知道感激，呸',\n",
       " '并不觉得关键…这个时候不应该想着解决问题吗?等战胜疫情考虑从哪里产生岂不是更好?',\n",
       " '意大利的医疗条件太差了，中国7天建了火神山医院，每位患者都是隔离的，中国🇨🇳最强👍的，哪个国家能和中国🇨🇳比！',\n",
       " '一个人五千万。先打钱，我估计下了战场的很多种医护人员都想去，而且不保证能治好，五十亿欧元能解决人手问题，',\n",
       " '真心希望意大利能挺过去，也希望其他国家挺过去！除了美丽坚。',\n",
       " '别人对我们幸灾乐祸的时候你连个屁都不敢放！',\n",
       " '意大利加油！',\n",
       " '你太冷血了，无论如何我们都要都要帮，一定要挺住啊',\n",
       " '我们的大夫快回来吧？快快回来吧，我怕你们也感染了，快快回来吧，你们帮了他们也不会感谢你们',\n",
       " '😁',\n",
       " '希望他们记住这个教训，别太热情了，又贴脸又xx的，还有别歧视戴口罩的人',\n",
       " '华人在意大利街头发口罩都没人要啊，不引起重视没办法',\n",
       " '加油',\n",
       " '正常医院各个科室做事都是留点留底，话不说死，没有十足的把握我感觉，应该不会',\n",
       " '作为一线医护人员家属，我求您积德真的',\n",
       " '看着意大利医疗简陋的图片，无比的感到祖国的强大！',\n",
       " '武汉前期肯定和他们差不多 但是后期明显控制下来了 他们这个是还在爆发期',\n",
       " '9',\n",
       " '，',\n",
       " '把好国门，加强防控，杜绝输入性病例出现，',\n",
       " '死亡率比中国高，中国有咋国家的国宝集中医，他们没有中医',\n",
       " '他们还不怕吗',\n",
       " '希望我们的医疗队员保护好自己，一个也不能少，加油！',\n",
       " '这评论区都特么什么鬼玩意儿。',\n",
       " '9%了',\n",
       " '天塌了，真的太恐怖了，好像是世界末日降临。',\n",
       " '他们那个封城跟我们的封城不一样',\n",
       " '加油意大利',\n",
       " '意大利的数据，为啥援引荷兰媒体的数据？',\n",
       " '意大利加油',\n",
       " '👏',\n",
       " '你这话有证据吗？没有证据可以算造谣',\n",
       " '阳台唱歌会传染病毒？',\n",
       " '你这么说你也真够冷默 你不圣母。你够没人味儿的。你就一点同情心没有吗。看你发出的这句话。真心替你的家人为你悲伤',\n",
       " '笑了少层皮？楼主表达的是被歧视了，你有流量上微博，没流量看新闻吗？你被你同学歧视了？',\n",
       " '若为自由故，甘愿死翘翘？',\n",
       " '我现在才知道原来姚晨那么喜欢吃鸭脖',\n",
       " '彻底沦陷了。希望意大利疫情能赶快得到控制，别再有大数据的确诊和死亡了。',\n",
       " '回复 @早起加蜂蜜水:国家派去是指导的，指导啊！不是上一线去送死啊！你这风凉话!',\n",
       " '没事，武汉高峰期时最多一天有一万多，增数越多说明离拐点越近，之后会一直下降',\n",
       " '意大利人民加油，胜利一定属于你们，中国可以战胜疫情，你们也一样，我爱你们！！加油！加油！加油！！！！！！！！',\n",
       " '老天保佑，赶紧控制住吧，太恐怖了',\n",
       " '我看你是站着说话不腰疼，传染病和地震支援不能相提并论，你这么圣母，你应该先报名啊，意大利人民欢迎你呢！慷他人之慨，你也是牛逼！',\n",
       " '太可怕了',\n",
       " '一个小国家感染这么多人，他的医疗人员已经崩溃了',\n",
       " '意大利跟西班牙真是欧洲增长双璧 官方一开始的放任受苦的还是人民',\n",
       " '我觉得这些幸灾乐祸，无视生命的人不配做善良包容的中国人！无论如何，人命无价，为逝者祈祷，为医者祈福。',\n",
       " '楼里有狗快气死了',\n",
       " '上下五千年中国人才是最聪明的！',\n",
       " '怎么接手？能保证意大利语和英语准确交流么？',\n",
       " '意大利的局面失控了。想靠中国的方法控制住局面几乎是不可能了。',\n",
       " '自己的媒体把自己忽悠瘸了',\n",
       " '该上大锅药了',\n",
       " '您的意思是意大利人民的命不是命还是我们同胞的命不是命？同样是救命，怎么就不能相提并论了？人家来汶川支援的时候能确定不会发生余震？起码我们过去还能保护好自己。我们应该相信我们过去的专家有能力能保护好自己~',\n",
       " '这个不是哦，发达国家医疗水平可以的，问题是现在医疗崩溃了医护人员不够物资也不够床位更加不够',\n",
       " '事实而已 真的玻璃心 去一线支援吧 满足你的普世心',\n",
       " '！',\n",
       " '在微博，展示的是极尽裸露的人性，最高贵的那部分和最低俗的那部分，难得有理性的声音。所以，层主，不管别人咋说，我挺你',\n",
       " '希望平安吧',\n",
       " '菩萨保佑人类早日摆脱这个疫情，保佑意大利，保佑我大中华',\n",
       " '这死亡率太可怕了',\n",
       " '唯一的好处，缓解老龄化',\n",
       " '这种，让我们帮它，就是个无底洞啊。继续这么下去，什么都会缺。哎！还有一堆人不听话，也不晓得派点军队管理这些到处跑的毒源',\n",
       " '不管什么原因，听到这样的新闻真的很难过，他不是冷的数字，是一条条生命啊，希望国际医疗组织能帮助他们，也一样我们派出去的医疗队平平安安，一个都不能少',\n",
       " '意大利一共才几千万人，这个感染人数确实有点多！',\n",
       " '真能装，不像你，表面伪君子，背后真小人',\n",
       " '希望意大利赶快控制疫情啊！这样下去真是好怕人',\n",
       " '意大利🇮🇹是重灾区了……',\n",
       " '看它头像，就不像你希望的那样，中国稍微有点错，他恨不得批判到死',\n",
       " '权衡利弊后得出的数据，避免引起恐慌，心里知道就行了',\n",
       " '我们幸灾乐祸你这种反中的畜牲赶快出门被车撞死！',\n",
       " '我不希望我们的医护人员在他们自己不重视导致这样的局面后去上他们的一线，他们既不想花钱又不重视并且大多数人还抱有歧视眼光认为该中国人去赎罪救治他们的时候，这样的付出与援助太廉价没有意义。人伦道德合理的救援可以，但至少他们自己解决不了的时候，求助该有求助的态度',\n",
       " '这可如何是好？',\n",
       " '现在最重要的是去意大利支援的中国医疗队，一定一定要做好完全措施',\n",
       " '美国之前都不检测所以没有爆发，不确诊就是流感可',\n",
       " '哎，现在我才觉得中国是真的强大了',\n",
       " '罗马挺住！',\n",
       " '意大利挺住',\n",
       " '希望我们出国支援的医护人员都能平安归来。[給你小心心]',\n",
       " '回复 @病入腠理:都是亚洲国家，还是文化方面的原因。。',\n",
       " '这可比中国严重多了，中国没这剧情 ，抱歉。',\n",
       " '真的可怕死亡率突破百分之九了，每1200个人就有一个患者，比中国高13倍，真的庆幸我是中国人，西方把“生命诚可贵，爱情价更高。若为自由故，二者皆可抛”这句话体现的淋漓尽致。',\n",
       " '口罩可以捐，设备可以捐，所有物资都可以捐，我们是有担当的大国，愿意帮助大家共度难关，。就是人坚决不能捐，我们的医护工作者不该再冒风险了',\n",
       " '长得速度和死亡速度持平啊，真牛',\n",
       " '去找欧盟吧，不要老逮着一家坑吧，心疼我们的医护人员',\n",
       " '欧美国家的数据只会更假',\n",
       " '赶快好起来吧',\n",
       " '你是意大利籍',\n",
       " '……不会团灭吧',\n",
       " '这个数据感觉疫情应该比我们想象中更早开始在意大利传播了……']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = str(time.strftime(\"%Y-%m-%d\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if not os.path.isdir(base_dir):\n",
    "    os.mkdir(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2e5dc8da67fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    time.sleep(1)\n",
    "    print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(topic:str, offset:int):\n",
    "        params = {\n",
    "        'aid':'24',\n",
    "        'app_name':'web_search',\n",
    "        'offset':offset,\n",
    "        'format':'json',\n",
    "        'keyword':topic,\n",
    "        'autoload':'true',\n",
    "        'count':'20',\n",
    "        'en_qc':'1',\n",
    "        'cur_tab': '1',\n",
    "        'from': 'search_tab',\n",
    "        'pd':'synthesis',\n",
    "        'timestamp': int(time.time()),\n",
    "#         '_signature': 'IbFHAAAgEBA3yUF75cndAiGwBhAAH7IJXfv09r0xnfIHXUO.wGRyqhIENMKOMyAu3iCJztEo-qyssj6DE9odGsrrvM9bgxjb8OTCJCZ2keUE1waSz2iIaY7SpaNVulSvUp5'\n",
    "        }\n",
    "        url = 'https://www.toutiao.com/api/search/content/?'\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params)\n",
    "            if response.status_code==200:\n",
    "                return response.json()\n",
    "        except requests.ConnectionError:\n",
    "            return None\n",
    "\n",
    "get_page('奶茶', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from pyquery import PyQuery as pq\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "wait = WebDriverWait(browser, 10)\n",
    "\n",
    "# 进入爬取页面\n",
    "def search():\n",
    "    try:\n",
    "        url = 'https://news.sina.com.cn/roll/#pageid=153&lid=2509&k=&num=50&page=1'\n",
    "        browser.get(url)\n",
    "        wait.until(EC.presence_of_element_located((By.ID, 'pL_Main')))\n",
    "        getDetail()\n",
    "        total = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '#d_list > div > span:nth-child(14) > a')))\n",
    "        return total.text\n",
    "    except TimeoutError:\n",
    "        return search()\n",
    "# 得到具体信息\n",
    "def getDetail():\n",
    "    html = pq(browser.page_source,parser=\"html\")\n",
    "    content = html.find('#d_list')\n",
    "    uls = content.find('ul').items()\n",
    "    for ul in uls:\n",
    "        lis = ul('li').items()\n",
    "        for li in lis:\n",
    "            news = {\n",
    "                'title': li.find('.c_tit a').text(),\n",
    "                'href': li.find('.c_tit a').attr('href'),\n",
    "                'time': li.find('.c_time').text()\n",
    "            }\n",
    "            print(news)\n",
    "# 爬取下一页\n",
    "def next_detail(page_number):\n",
    "    try:\n",
    "        nextBotton = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, '#d_list > div > span:last-child > a')))\n",
    "        nextBotton.click()\n",
    "        wait.until(EC.text_to_be_present_in_element((By.CSS_SELECTOR, '#d_list > div > span.pagebox_num_nonce'), str(page_number)))\n",
    "        getDetail()\n",
    "    except TimeoutException:\n",
    "        next_detail(page_number)\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        total = search()\n",
    "        total = int(total)\n",
    "        for i in range(2, total + 1):\n",
    "            next_detail(i)\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "    finally:\n",
    "        browser.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#存入本地txt\n",
    "def write_article(data,flag):\n",
    "    if flag == 1:\n",
    "        file_name = 'newscontent.txt'\n",
    "        f = open(file_name, 'a', encoding='utf-8')\n",
    "        f.write(data)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.close()\n",
    "    elif flag == 2:\n",
    "        file_name = 'newscomment.csv'\n",
    "        name = ['comment','agree']\n",
    "        comments = pd.DataFrame(list(zip(*data)),columns=name)\n",
    "        comments.to_csv(file_name)\n",
    "    else:\n",
    "        file_name = 'newscomment.txt'\n",
    "        f = open(file_name, 'a', encoding='utf-8')\n",
    "        f.write(data)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def get_content(url):\n",
    "    try:\n",
    "        html = urllib.request.urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        obj = BeautifulSoup(html.read(),\"html.parser\")\n",
    "    except HTTPError as f:\n",
    "        return None\n",
    "    nameList = obj.findAll(\"div\", {\"class\": \"article\"})\n",
    "    for name in nameList:\n",
    "        print(name.get_text())\n",
    "        str = name.get_text()\n",
    "        write_article(str,1)\n",
    "get_content(\"https://finance.sina.com.cn/chanjing/gsnews/2019-12-11/doc-iihnzahi6659560.shtml\")\n",
    "\n",
    "\n",
    "\n",
    "#定义空数组 用来存放评论和评论获赞的数量\n",
    "listAll=[]\n",
    "listComments = []\n",
    "listAgree = []\n",
    "\n",
    "#获取当前页的评论 最多三条热门\n",
    "comments = requests.get(\"https://comment.sina.com.cn/page/info?version=1&format=json&channel=cj&newsid=comos-ihnzahi6659560&group=undefined&compress=0&ie=utf-8&oe=utf-8&page=1&page_size=3&t_size=3&h_size=3&thread=1&uid=unlogin_user\")\n",
    "comments.encoding=('utf-8')\n",
    "comments.text\n",
    "jd = json.loads(comments.text)\n",
    "#print(jd)\n",
    "for x in range(3):\n",
    "    print(jd['result']['hot_list'][x]['content'])\n",
    "    str1 = jd['result']['hot_list'][x]['content']\n",
    "    str2 = jd['result']['hot_list'][x]['agree']\n",
    "    write_article(str1,3)\n",
    "    listComments.append(str1)\n",
    "    listAgree.append(str2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#打开更多评论查看全部评论\n",
    "comments2 = requests.get(\"http://comment.sina.com.cn/page/info?version=1&format=json&channel=cj&newsid=comos-ihnzahi6659560&group=0&compress=0&ie=utf-8&oe=utf-8&page=1&page_size=10&t_size=3&h_size=3&thread=1&uid=unlogin_user\")\n",
    "comments2.encoding=('utf-8')\n",
    "comments.text\n",
    "jd1 = json.loads(comments2.text)\n",
    "count = jd1['result']['count']['thread_show']\n",
    "#print(jd1)\n",
    "\n",
    "#-5防止下标越界\n",
    "for x in range(count-5):\n",
    "    print(jd1['result']['cmntlist'][x]['content'])\n",
    "    str1 = jd1['result']['cmntlist'][x]['content']\n",
    "    str2 = jd1['result']['cmntlist'][x]['agree']\n",
    "    write_article(str1,3)\n",
    "    listComments.append(str1)\n",
    "    listAgree.append(str2)\n",
    "\n",
    "#把评论和赞放到一个数组里面\n",
    "listAll.append(listComments)\n",
    "listAll.append(listAgree)\n",
    "\n",
    "\n",
    "#将评论写入cvs文件\n",
    "#print(listAll)\n",
    "write_article(listAll,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"newscomment.csv\")\n",
    "data.head()\n",
    "#情感划分 赞大于300的给1 赞小于三百的给0\n",
    "def make_label(agree):\n",
    " if agree > 300:\n",
    "    return 1\n",
    " else:\n",
    "    return 0\n",
    "\n",
    "data['sentiment'] = data.agree.apply(make_label)\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "#结巴分词\n",
    "def chinese_word_cut(mytext):\n",
    " return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "data['cut_comment'] = data.comment.apply(chinese_word_cut)\n",
    "\n",
    "#划分数据集\n",
    "X = data['cut_comment']\n",
    "y = data.sentiment\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "\n",
    "#数据处理\n",
    "def get_custom_stopwords(stop_words_file):\n",
    " with open(stop_words_file,'r',encoding='utf-8') as f:\n",
    "    stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    " return custom_stopwords_list\n",
    "\n",
    "stop_words_file = '哈工大停用词表.txt'\n",
    "stopwords = get_custom_stopwords(stop_words_file)\n",
    "\n",
    "vect = CountVectorizer(max_df = 0.8,\n",
    "                       min_df = 3,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
    "                       stop_words=frozenset(stopwords))\n",
    "\n",
    "test = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names())\n",
    "test.head()\n",
    "\n",
    "\n",
    "#训练模式  朴素贝叶斯算法\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "nb.fit(X_train_vect, y_train)\n",
    "train_score = nb.score(X_train_vect, y_train)\n",
    "#print(train_score)\n",
    "\n",
    "#测试数据\n",
    "X_test_vect = vect.transform(X_test)\n",
    "#print(nb.score(X_test_vect, y_test))\n",
    "\n",
    "#使用snownlp插件包\n",
    "data = open(\"newscomment.txt\",encoding='utf-8')\n",
    "s = data.read()\n",
    "snownlp = SnowNLP(s)\n",
    "print(snownlp.sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlconda34f4c0e8019f49848bc5a3e96f43aeac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
